[["index.html", "Practical Statistics for Data Scientists Book Club Welcome", " Practical Statistics for Data Scientists Book Club The R4DS Online Learning Community 2021-05-17 Welcome This is a companion for the book Practical Statistics for Data Scientists by Peter Bruce, Andrew Bruce, and Peter Gedeck (O’Reilly, copyright 2020, 978-1-492-07294-2). This companion is available at r4ds.io/ps4ds. This website is being developed by the R4DS Online Learning Community. Follow along, and join the community to participate. This companion follows the R4DS Online Learning Community Code of Conduct. "],["book-club-meetings.html", "Book club meetings", " Book club meetings Each week, a volunteer will present a chapter from the book (or part of a chapter). This is the best way to learn the material. Presentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter. More information about how to present is available in the github repo. Presentations will be recorded, and will be available on the R4DS Online Learning Community YouTube Channel. "],["sample-code.html", "Sample code", " Sample code Sample code is available at github.com/gedeck/practical-statistics-for-data-scientists You can install all packages used by these notes and recommended by the book authors1: install.packages(&quot;remotes&quot;) remotes::install_github(&quot;r4ds/bookclub-ps4ds&quot;) remove.packages(&quot;ps4ds&quot;) # This isn&#39;t really a package. Chapter 5 uses {DMwR}, which is currently unavailable on CRAN. We’ll confirm when we get there, but I’m guessing {DMwR2} will work instead.↩︎ "],["st-edition-vs-2nd-edition.html", "1st edition vs 2nd edition", " 1st edition vs 2nd edition Here we’ll attempt to document differences between 1e and 2e. 2e added Python example code Some sections and subsections have slight name changes Chapter 1: New subsection in 1.6, “Probability” Chapter 2: New sections “Chi-Square Distribution” &amp; “F-Distribution” Chapter 4: New subsection in 4.2, “Further Reading” Chapter 7: New subsection in 7.1, “Correspondence Analysis” "],["pace.html", "Pace", " Pace Chapters are long, but not always dense. We’ll try to cover 1 chapter/week, but… …It’s ok to split chapters when they feel like too much. "],["exploratory-data-analysis.html", "Chapter 1 Exploratory Data Analysis", " Chapter 1 Exploratory Data Analysis Learning objectives: Classify data as numeric or categorical. Compare and contrast estimates of location. Compare and contrast estimates of variability. Visualize data distributions. Visualize categorical data. Use correlation coefficients to measure association between two variables. Visualize data distributions in two dimensions. "],["structured-data.html", "1.1 Structured Data", " 1.1 Structured Data Software classifies data by type. Numeric (continuous or discrete) Categorical (binary, ordinal, neither) Rectangular data = typical frame of reference for data science. Called a data.frame in R Rows are records (aka observations, cases, instances) Columns are features (aka variables, attributes, predictors in some cases) Lots of synonyms in stats and data science for same things. "],["estimates-of-location.html", "1.2 Estimates of Location", " 1.2 Estimates of Location Most basic = mean. dataset &lt;- c(3, 4, 1, 2, 10) mean(dataset) # (3 + 4 + 1 + 2 + 10)/5 = 20/5 ## [1] 4 Trimming helps eliminate outliers mean(dataset, trim = 1/5) # (2 + 3 + 4)/3 = 9/3 ## [1] 3 Weight to: Down-weight high-variability values. Up-weight under-represented values. weights &lt;- c(1, 1, 11, 1, 1) weighted.mean(dataset, weights) # (3 + 4 + 11 + 2 + 10)/15 = 30/15 ## [1] 2 Median: sort then choose middle value. median(dataset) # 1, 2, (3), 4, 10 ## [1] 3 Weighted median: similar to weighted mean, but more complicated. # Sort then weight then middle of weight. 1*11, 2*1, 3*1, 4*1, 10*1 matrixStats::weightedMedian(dataset, weights) ## [1] 1.333333 Technically it interpolates in-between values. matrixStats::weightedMedian(dataset, weights, interpolate = TRUE) ## [1] 1.333333 Can tell it not to interpolate to simplify. matrixStats::weightedMedian(dataset, weights, interpolate = FALSE) ## [1] 1 # Equivalent to repeating values weight times. median(c(rep(1, 11), 2, 3, 4, 10)) ## [1] 1 Their sample code is available at github.com/gedeck/practical-statistics-for-data-scientists "],["estimates-of-variability.html", "1.3 Estimates of Variability", " 1.3 Estimates of Variability Variability (aka dispersion) = are values clustered or spread out? 1.3.1 SD &amp; Friends Variance = average of squared deviations, \\(s^2 = \\frac{\\sum_{i=1}^{n}{(x_{1}-\\bar{x})^2}}{n-1}\\) s_squared &lt;- var(dataset) s_squared ## [1] 12.5 Standard deviation = square root of variance, \\(s = \\sqrt{variance}\\) s &lt;- sd(dataset) s ## [1] 3.535534 s == sqrt(s_squared) ## [1] TRUE Median absolute deviation from the median (MAD) is robust to outliers. mad(dataset) ## [1] 1.4826 Wait, why did that return the standard scale factor? dataset is c(1, 2, 3, 4, 10) The difference between any 2 values is 1 (except the outlier) 1 * 1.4826 = 1.4826 1.3.2 Percentiles &amp; Friends Percentiles = quantiles, \\(P\\%\\) of values are \\(&lt;= x\\) x &lt;- sample(1:100, 100, replace = TRUE) y &lt;- rnorm(100, mean = 50, sd = 20) quantile(x, probs = seq(0, 1, 0.1)) ## 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% ## 1.0 10.0 19.0 29.1 37.2 51.0 58.8 69.0 78.2 87.0 100.0 quantile(y, probs = seq(0, 1, 0.1)) ## 0% 10% 20% 30% 40% 50% 60% ## -3.166691 24.188059 36.258159 44.472727 49.181259 54.851565 59.157381 ## 70% 80% 90% 100% ## 63.589100 67.240193 76.555766 111.670856 quantile(x) # quartile ## 0% 25% 50% 75% 100% ## 1.00 23.75 51.00 75.25 100.00 IQR(x) # They introduce this later but I like it here. ## [1] 51.5 "],["histograms-friends.html", "1.4 Histograms &amp; Friends", " 1.4 Histograms &amp; Friends state &lt;- read.csv(&quot;data/state.csv&quot;) head(state) ## State Population Murder.Rate Abbreviation ## 1 Alabama 4779736 5.7 AL ## 2 Alaska 710231 5.6 AK ## 3 Arizona 6392017 4.7 AZ ## 4 Arkansas 2915918 5.6 AR ## 5 California 37253956 4.4 CA ## 6 Colorado 5029196 2.8 CO library(ggplot2) ggplot(state, aes(y = Population/1000000)) + geom_boxplot() + ylab(&quot;Population (millions)&quot;) ggplot(state, aes(x = Population/1000000)) + geom_histogram( aes(y = after_stat(density)), bins = 10, fill = &quot;white&quot;, color = &quot;black&quot; ) + geom_density(fill = &quot;blue&quot;, alpha = 0.5) + xlab(&quot;Population (millions)&quot;) "],["visualizing-categorical-data.html", "1.5 Visualizing Categorical Data", " 1.5 Visualizing Categorical Data Bar charts are boring. We’ll see some examples related to this in 2D. "],["correlation.html", "1.6 Correlation", " 1.6 Correlation library(corrplot) ## corrplot 0.88 loaded library(dplyr, quietly = TRUE) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union sp500_px &lt;- read.csv(&quot;data/sp500_data.csv.gz&quot;) %&gt;% as_tibble() sp500_sym &lt;- read.csv(&quot;data/sp500_sectors.csv&quot;, stringsAsFactors = FALSE) %&gt;% as_tibble() etfs &lt;- sp500_px %&gt;% filter(X &gt; &quot;2012-07-01&quot;) %&gt;% select( any_of( sp500_sym %&gt;% filter(sector == &quot;etf&quot;) %&gt;% pull(symbol) ) ) corrplot(cor(etfs), method = &quot;ellipse&quot;) "],["d-distributions.html", "1.7 2D Distributions", " 1.7 2D Distributions https://xkcd.com/1967/ "],["meeting-videos.html", "1.8 Meeting Videos", " 1.8 Meeting Videos 1.8.1 Cohort 1 Meeting chat log CHAT LOG "],["data-and-sampling-distributions.html", "Chapter 2 Data and Sampling Distributions", " Chapter 2 Data and Sampling Distributions Learning objectives: TBD "],["slide-2.html", "2.1 SLIDE 2", " 2.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3.html", "2.2 SLIDE 3", " 2.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-1.html", "2.3 Meeting Videos", " 2.3 Meeting Videos 2.3.1 Cohort 1 Meeting chat log CHAT LOG "],["statistical-experiments-and-significance-testing.html", "Chapter 3 Statistical Experiments and Significance Testing", " Chapter 3 Statistical Experiments and Significance Testing Learning objectives: TBD "],["slide-2-1.html", "3.1 SLIDE 2", " 3.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3-1.html", "3.2 SLIDE 3", " 3.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-2.html", "3.3 Meeting Videos", " 3.3 Meeting Videos 3.3.1 Cohort 1 Meeting chat log CHAT LOG "],["regression-and-prediction.html", "Chapter 4 Regression and Prediction", " Chapter 4 Regression and Prediction Learning objectives: TBD "],["slide-2-2.html", "4.1 SLIDE 2", " 4.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3-2.html", "4.2 SLIDE 3", " 4.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-3.html", "4.3 Meeting Videos", " 4.3 Meeting Videos 4.3.1 Cohort 1 Meeting chat log CHAT LOG "],["classification.html", "Chapter 5 Classification", " Chapter 5 Classification Learning objectives: TBD "],["slide-2-3.html", "5.1 SLIDE 2", " 5.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3-3.html", "5.2 SLIDE 3", " 5.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-4.html", "5.3 Meeting Videos", " 5.3 Meeting Videos 5.3.1 Cohort 1 Meeting chat log CHAT LOG "],["statistical-machine-learning.html", "Chapter 6 Statistical Machine Learning", " Chapter 6 Statistical Machine Learning Learning objectives: TBD "],["slide-2-4.html", "6.1 SLIDE 2", " 6.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3-4.html", "6.2 SLIDE 3", " 6.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-5.html", "6.3 Meeting Videos", " 6.3 Meeting Videos 6.3.1 Cohort 1 Meeting chat log CHAT LOG "],["unsupervised-learning.html", "Chapter 7 Unsupervised Learning", " Chapter 7 Unsupervised Learning Learning objectives: TBD "],["slide-2-5.html", "7.1 SLIDE 2", " 7.1 SLIDE 2 ADD SLIDE CONTENTS "],["slide-3-5.html", "7.2 SLIDE 3", " 7.2 SLIDE 3 MORE SLIDE CONTENTS "],["meeting-videos-6.html", "7.3 Meeting Videos", " 7.3 Meeting Videos 7.3.1 Cohort 1 Meeting chat log CHAT LOG "]]
